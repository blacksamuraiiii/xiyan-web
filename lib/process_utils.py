import os
import io
import base64
import logging
import pandas as pd
import numpy as np
import chardet
import fitz  # PyMuPDF
import time # å¯¼å…¥ time æ¨¡å—
from .llm_utils import call_vl_api
from .db_utils import insert_dataframe_to_db, check_table_exists

# logæ–‡ä»¶é…ç½®
logger = logging.getLogger(__name__)

# --- ç»Ÿä¸€é”™è¯¯å¤„ç†å‡½æ•° ---
def handle_error(st, error_message, exception=None, error_code=None, user_suggestion=None):
    """ç»Ÿä¸€çš„é”™è¯¯å¤„ç†å‡½æ•°ï¼Œæä¾›æ ‡å‡†åŒ–çš„é”™è¯¯æ¶ˆæ¯æ ¼å¼
    
    Args:
        st: Streamlitå¯¹è±¡
        error_message: é”™è¯¯æ¶ˆæ¯
        exception: å¼‚å¸¸å¯¹è±¡ï¼ˆå¯é€‰ï¼‰
        error_code: é”™è¯¯ä»£ç ï¼ˆå¯é€‰ï¼‰
        user_suggestion: ç”¨æˆ·å»ºè®®ï¼ˆå¯é€‰ï¼‰
    """
    # æ„å»ºå®Œæ•´çš„é”™è¯¯æ¶ˆæ¯
    full_message = error_message
    
    if error_code:
        full_message = f"é”™è¯¯ä»£ç : {error_code} - {full_message}"
    
    if user_suggestion:
        full_message += f"\n\nğŸ’¡ å»ºè®®: {user_suggestion}"
    
    # æ˜¾ç¤ºç»™ç”¨æˆ·
    st.error(full_message)
    
    # è®°å½•æ—¥å¿—
    if exception:
        logger.error(f"{error_message} - Exception: {str(exception)}", exc_info=True)
    else:
        logger.error(error_message)

def show_success(st, success_message, details=None):
    """ç»Ÿä¸€çš„æˆåŠŸæ¶ˆæ¯æ˜¾ç¤ºå‡½æ•°
    
    Args:
        st: Streamlitå¯¹è±¡
        success_message: æˆåŠŸæ¶ˆæ¯
        details: è¯¦ç»†ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
    """
    if details:
        full_message = f"âœ… {success_message}\n\n{details}"
    else:
        full_message = f"âœ… {success_message}"
    
    st.success(full_message)
    logger.info(success_message)

def show_warning(st, warning_message, details=None):
    """ç»Ÿä¸€çš„è­¦å‘Šæ¶ˆæ¯æ˜¾ç¤ºå‡½æ•°
    
    Args:
        st: Streamlitå¯¹è±¡
        warning_message: è­¦å‘Šæ¶ˆæ¯
        details: è¯¦ç»†ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
    """
    if details:
        full_message = f"âš ï¸ {warning_message}\n\n{details}"
    else:
        full_message = f"âš ï¸ {warning_message}"
    
    st.warning(full_message)
    logger.warning(warning_message)

def show_info(st, info_message, details=None):
    """ç»Ÿä¸€çš„ä¿¡æ¯æ¶ˆæ¯æ˜¾ç¤ºå‡½æ•°
    
    Args:
        st: Streamlitå¯¹è±¡
        info_message: ä¿¡æ¯æ¶ˆæ¯
        details: è¯¦ç»†ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
    """
    if details:
        full_message = f"â„¹ï¸ {info_message}\n\n{details}"
    else:
        full_message = f"â„¹ï¸ {info_message}"
    
    st.info(full_message)
    logger.info(info_message)


# --- ä¸»å¤„ç†å‡½æ•° ---
def process_uploaded_files(st, uploaded_files, conn, vl_client, vl_model_name):
    """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶åˆ—è¡¨ï¼Œæ ¹æ®ç±»å‹åˆ†å‘å¤„ç†ï¼Œå¹¶å¤„ç†è¡¨å­˜åœ¨é€»è¾‘ã€‚"""
    if not conn:
        st.error("æ•°æ®åº“æœªè¿æ¥ï¼Œæ— æ³•å¤„ç†æ–‡ä»¶ã€‚")
        return
    if not uploaded_files:
        st.info("è¯·å…ˆä¸Šä¼ æ–‡ä»¶ã€‚")
        return

    processed_tables = []
    files_pending_confirmation = []

    # ç¬¬ä¸€éï¼šå¤„ç†æ–‡ä»¶ï¼Œè¯†åˆ«éœ€è¦ç”¨æˆ·ç¡®è®¤çš„è¡¨
    for uploaded_file in uploaded_files:
        file_type = uploaded_file.type
        file_name = uploaded_file.name
        logger.info(f"Processing file: {file_name}, type: {file_type}")

        if file_type in ['text/csv', 'application/vnd.ms-excel', 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet']:
            # è¡¨æ ¼æ–‡ä»¶å¯èƒ½äº§ç”Ÿå¤šä¸ªè¡¨ï¼ˆExcel sheetsï¼‰
            base_file_name = os.path.splitext(file_name)[0]
            original_base_table_name = base_file_name

            if file_name.endswith('.csv'):
                # æ£€æŸ¥CSVå¯¹åº”çš„è¡¨æ˜¯å¦å­˜åœ¨
                sanitized_name = ''.join(filter(str.isalnum, original_base_table_name)).lower()
                if sanitized_name and check_table_exists(conn, sanitized_name):
                    files_pending_confirmation.append({'file': uploaded_file, 'type': 'csv', 'original_name': original_base_table_name})
                else:
                    # è¡¨ä¸å­˜åœ¨ï¼Œç›´æ¥å¤„ç†
                    result = process_tabular_file(st, uploaded_file, conn)
                    if result: processed_tables.extend(result)
            elif file_name.endswith(('.xls', '.xlsx')):
                 # å¢å¼ºçš„Excelé¢„æ£€æŸ¥ï¼šå¤šå¼•æ“æ”¯æŒ
                 engines = ['calamine', 'openpyxl', 'xlrd']
                 excel_data = None
                 successful_engine = None
                 
                 for engine in engines:
                     try:
                         uploaded_file.seek(0)
                         excel_data = pd.read_excel(uploaded_file, sheet_name=None, engine=engine)
                         if excel_data:
                             successful_engine = engine
                             logger.info(f"Successfully read Excel {file_name} using engine: {engine} during pre-check")
                             break
                     except ImportError:
                         continue
                     except Exception as e:
                         logger.warning(f"Engine {engine} failed for {file_name} during pre-check: {e}")
                         continue
                 
                 if excel_data is None:
                     st.error(f"æ— æ³•è¯»å–Excelæ–‡ä»¶ '{file_name}'ï¼Œå·²å°è¯•æ‰€æœ‰å¯ç”¨çš„è§£æå¼•æ“ã€‚è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚")
                     logger.error(f"All Excel engines failed for {file_name} during pre-check")
                     continue
                     
                 if excel_data:
                     non_empty_sheets = [(name, df) for name, df in excel_data.items() if not df.empty]
                     for sheet_name, df_sheet in non_empty_sheets:
                         # ç›´æ¥ä½¿ç”¨sheetåç§°ç”Ÿæˆè¡¨å
                         cleaned_sheet_name = ''.join(filter(str.isalnum, str(sheet_name))).lower()
                         original_table_name = cleaned_sheet_name if cleaned_sheet_name else f"sheet_{len(processed_tables) + len(files_pending_confirmation) + 1}"
                         
                         sanitized_name = ''.join(filter(str.isalnum, original_table_name)).lower()
                         if sanitized_name and check_table_exists(conn, sanitized_name):
                             files_pending_confirmation.append({'file': uploaded_file, 'type': 'excel_sheet', 'original_name': original_table_name, 'sheet_name': sheet_name, 'df': df_sheet})
                         else:
                             # è¡¨ä¸å­˜åœ¨ï¼Œç›´æ¥å¤„ç†è¯¥sheet
                             if insert_dataframe_to_db(st, df_sheet, sanitized_name, conn, if_exists='replace'):
                                  st.success(f"EXCELè¡¨ '{sheet_name}' å·²æˆåŠŸåˆ›å»ºè¡¨ '{sanitized_name}'ã€‚")  # ç§»é™¤äº†æ–‡ä»¶åæ˜¾ç¤º
                                  processed_tables.append(sanitized_name)
                             else:
                                  st.error(f"åˆ›å»ºè¡¨ '{sanitized_name}' ä»å·¥ä½œè¡¨ '{sheet_name}' å¤±è´¥ã€‚")

        elif file_type.startswith('image/') or file_type == 'application/pdf':
            # OCR æ–‡ä»¶
            original_table_name = os.path.splitext(file_name)[0]
            sanitized_name = ''.join(filter(str.isalnum, original_table_name)).lower()
            if sanitized_name and check_table_exists(conn, sanitized_name):
                 files_pending_confirmation.append({'file': uploaded_file, 'type': 'ocr', 'original_name': original_table_name})
            else:
                 # è¡¨ä¸å­˜åœ¨ï¼Œç›´æ¥å¤„ç†
                 result = process_ocr(st, uploaded_file, conn, vl_client, vl_model_name)
                 if result: processed_tables.append(result)
        else:
            st.warning(f"è·³è¿‡ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_name}")

    # ç¬¬äºŒéï¼šå¤„ç†éœ€è¦ç”¨æˆ·ç¡®è®¤çš„æ–‡ä»¶
    if files_pending_confirmation:
        st.divider()
        st.subheader("ä»¥ä¸‹æ–‡ä»¶å¯¹åº”çš„æ•°æ®åº“è¡¨å·²å­˜åœ¨ï¼Œè¯·ç¡®è®¤æ“ä½œï¼š")
        
        all_confirmed = True # è·Ÿè¸ªæ˜¯å¦æ‰€æœ‰å¾…ç¡®è®¤é¡¹éƒ½å·²å¤„ç†
        results_from_confirmation = []

        for item in files_pending_confirmation:
            uploaded_file = item['file']
            original_name = item['original_name']
            file_type = item['type']
            
            # è°ƒç”¨é‡æ„åçš„ _handle_table_existence
            proceed, final_table_name, if_exists_strategy = _handle_table_existence(st, conn, original_name)

            if if_exists_strategy == 'pending':
                all_confirmed = False # åªè¦æœ‰ä¸€ä¸ªå¾…å®šï¼Œå°±ä¸æ˜¯å…¨éƒ¨ç¡®è®¤
                # ä¸éœ€è¦ç«‹å³å¤„ç†ï¼Œç­‰å¾…ä¸‹ä¸€æ¬¡streamlitè¿è¡Œå¾ªç¯
            elif proceed:
                # ç”¨æˆ·å·²ç¡®è®¤ï¼Œæ‰§è¡Œæ“ä½œ
                if file_type == 'csv':
                    # éœ€è¦é‡æ–°è¯»å–æ–‡ä»¶å†…å®¹ï¼Œä½¿ç”¨å¢å¼ºçš„CSVè§£æé€»è¾‘
                    try:
                        uploaded_file.seek(0) # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
                        raw_data = uploaded_file.read()
                        result = chardet.detect(raw_data)
                        detected_encoding = result['encoding']
                        
                        # ä½¿ç”¨ç›¸åŒçš„å¤šç§ç¼–ç å°è¯•æœºåˆ¶
                        encodings_to_try = ['utf-8', 'gbk', 'gb2312', 'latin1', detected_encoding]
                        encodings_to_try = [enc for enc in encodings_to_try if enc is not None]
                        
                        df = None
                        successful_encoding = None
                        
                        for encoding in encodings_to_try:
                            try:
                                uploaded_file.seek(0)
                                df = pd.read_csv(io.BytesIO(raw_data), encoding=encoding, escapechar='\\')
                                
                                if all(isinstance(col, int) for col in df.columns) or len(df) == 0:
                                    uploaded_file.seek(0)
                                    df = pd.read_csv(io.BytesIO(raw_data), encoding=encoding, escapechar='\\', header=None)
                                    df.columns = [f'col_{i}' for i in range(len(df.columns))]
                                
                                if not df.empty and len(df.columns) > 0:
                                    successful_encoding = encoding
                                    break
                                    
                            except UnicodeDecodeError:
                                continue
                            except Exception:
                                continue
                        
                        if df is None:
                            st.error(f"æ— æ³•é‡æ–°è¯»å–ç¡®è®¤åçš„CSVæ–‡ä»¶ '{uploaded_file.name}'")
                            logger.error(f"Failed to re-read confirmed CSV {uploaded_file.name}")
                            continue
                        
                        if insert_dataframe_to_db(st, df, final_table_name, conn, if_exists=if_exists_strategy):
                            st.success(f"CSV æ–‡ä»¶ '{uploaded_file.name}' å·²æˆåŠŸæ“ä½œè¡¨ '{final_table_name}' (ç­–ç•¥: {if_exists_strategy})ã€‚")
                            results_from_confirmation.append(final_table_name)
                        else:
                            st.error(f"æ“ä½œ CSV æ–‡ä»¶ '{uploaded_file.name}' åˆ°è¡¨ '{final_table_name}' å¤±è´¥ã€‚")
                    except Exception as e:
                        st.error(f"å¤„ç†ç¡®è®¤åçš„ CSV æ–‡ä»¶ '{uploaded_file.name}' æ—¶å‡ºé”™: {e}")
                        logger.error(f"Error processing confirmed CSV {uploaded_file.name}: {e}", exc_info=True)
                
                elif file_type == 'excel_sheet':
                    df_sheet = item['df']
                    sheet_name = item['sheet_name']
                    base_file_name = os.path.splitext(uploaded_file.name)[0]
                    if insert_dataframe_to_db(st, df_sheet, final_table_name, conn, if_exists=if_exists_strategy):
                        st.success(f"EXCELè¡¨ '{base_file_name}'-'{sheet_name}' å·²æˆåŠŸæ“ä½œè¡¨ '{final_table_name}' (ç­–ç•¥: {if_exists_strategy})ã€‚")
                        results_from_confirmation.append(final_table_name)
                    else:
                        st.error(f"æ“ä½œå·¥ä½œè¡¨ '{sheet_name}' åˆ°è¡¨ '{final_table_name}' å¤±è´¥ã€‚")

                elif file_type == 'ocr':
                     # å¯¹äºOCRï¼Œéœ€è¦é‡æ–°æ‰§è¡ŒOCRæµç¨‹ï¼Œå› ä¸ºç»“æœæœªå­˜å‚¨
                     result = process_ocr(st, uploaded_file, conn, vl_client, vl_model_name, force_process=True, target_table_name=final_table_name, ocr_if_exists=if_exists_strategy)
                     if result: results_from_confirmation.append(result)
            
            elif if_exists_strategy == 'skip':
                 # ç”¨æˆ·ç¡®è®¤è·³è¿‡
                 st.info(f"å·²è·³è¿‡æ–‡ä»¶ '{uploaded_file.name}' (ç±»å‹: {file_type}) çš„æ•°æ®åº“æ“ä½œã€‚")
                 # æ ‡è®°ä¸ºå·²å¤„ç†ï¼ˆè·³è¿‡ä¹Ÿæ˜¯ä¸€ç§å¤„ç†ï¼‰
            
            # å¦‚æœæ˜¯ 'fail' æˆ–å…¶ä»–æœªå¤„ç†æƒ…å†µï¼Œä¹Ÿç®—å¤„ç†å®Œæˆï¼ˆå¤±è´¥å¤„ç†ï¼‰

            # æ·»åŠ åˆ†éš”çº¿ï¼Œä½¿æ¯ä¸ªæ–‡ä»¶çš„ç¡®è®¤å—æ›´æ¸…æ™°
            st.divider()
        
        processed_tables.extend(results_from_confirmation)

        # if not all_confirmed:
        #     st.info("éƒ¨åˆ†æ–‡ä»¶éœ€è¦æ‚¨ç¡®è®¤æ“ä½œåæ‰èƒ½ç»§ç»­å¤„ç†ã€‚")

    st.divider()
    if processed_tables:
        st.success(f"æ–‡ä»¶å¤„ç†å®Œæˆã€‚æˆåŠŸæ“ä½œçš„è¡¨: {', '.join(processed_tables)}")
    else:
        st.info("æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæ¯•ï¼Œæ²¡æœ‰æ–°çš„æ•°æ®åº“è¡¨è¢«æ“ä½œæˆ–åˆ›å»ºï¼ˆå¯èƒ½è¢«è·³è¿‡æˆ–å¤„ç†å¤±è´¥ï¼‰ã€‚")

# --- è¾…åŠ©å‡½æ•° --- 
def _handle_table_existence(st, conn, original_table_name):
    """æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™å‘ç”¨æˆ·æ˜¾ç¤ºé€‰é¡¹å¹¶è¿”å›å¤„ç†æ–¹å¼ã€‚

    Args:
        st: Streamlit object.
        conn: Database connection.
        original_table_name (str): ç”¨æˆ·æä¾›çš„åŸå§‹è¡¨åï¼ˆæœªæ¸…ç†ï¼‰ã€‚

    Returns:
        tuple: (proceed: bool, final_table_name: str, if_exists_strategy: str)
               proceed: æ˜¯å¦ç»§ç»­æ•°æ®åº“æ“ä½œã€‚
               final_table_name: æœ€ç»ˆä½¿ç”¨çš„è¡¨åï¼ˆå¯èƒ½è¢«ç”¨æˆ·ä¿®æ”¹ï¼‰ã€‚
               if_exists_strategy: ç”¨æˆ·é€‰æ‹©çš„å¤„ç†ç­–ç•¥ ('replace', 'append', 'fail', 'rename', 'skip', 'pending')ã€‚
               å¦‚æœç”¨æˆ·é€‰æ‹©è·³è¿‡æˆ–å–æ¶ˆï¼Œè¿”å› (False, final_table_name, 'skip')
               å¦‚æœç­‰å¾…ç”¨æˆ·è¾“å…¥æˆ–ç¡®è®¤ï¼Œè¿”å› (False, final_table_name, 'pending')
    """
    # æ¸…ç†åŸå§‹è¡¨åä»¥è¿›è¡Œæ£€æŸ¥å’Œé»˜è®¤ä½¿ç”¨
    sanitized_base_name = ''.join(filter(str.isalnum, original_table_name)).lower()
    if not sanitized_base_name:
        st.error(f"æ— æ³•ä» '{original_table_name}' ç”Ÿæˆæœ‰æ•ˆçš„é»˜è®¤è¡¨åã€‚è¯·åœ¨ä¸‹æ–¹æ‰‹åŠ¨æŒ‡å®šã€‚")
        sanitized_base_name = f"table_{int(time.time())}" # æä¾›ä¸€ä¸ªå¤‡ç”¨åŸºç¡€

    # ä½¿ç”¨ session state æ¥å­˜å‚¨ç”¨æˆ·é€‰æ‹©å’Œç¡®è®¤çŠ¶æ€ï¼Œé¿å…æ§ä»¶çŠ¶æ€é‡ç½®é—®é¢˜
    # ä¸ºæ¯ä¸ªè¡¨ç”Ÿæˆå”¯ä¸€çš„ session key
    session_key_base = f"handle_table_{original_table_name.replace('.', '_').replace(' ', '_')}" # ç¡®ä¿keyçš„å”¯ä¸€æ€§
    action_key = f"{session_key_base}_action"
    rename_key = f"{session_key_base}_rename_input"
    confirm_key = f"{session_key_base}_confirm_button"
    confirmed_key = f"{session_key_base}_confirmed" # æ–°å¢ï¼šè·Ÿè¸ªç¡®è®¤çŠ¶æ€çš„key

    # åˆå§‹åŒ– session state (å¦‚æœä¸å­˜åœ¨)
    if action_key not in st.session_state:
        st.session_state[action_key] = 'æ›¿æ¢ç°æœ‰è¡¨' # é»˜è®¤é€‰é¡¹
    if rename_key not in st.session_state:
        st.session_state[rename_key] = f"{sanitized_base_name}_new"
    if confirmed_key not in st.session_state:
        st.session_state[confirmed_key] = False # åˆå§‹åŒ–ç¡®è®¤çŠ¶æ€ä¸º False

    table_exists = check_table_exists(conn, sanitized_base_name)

    if table_exists is None: # Error during check
        st.error(f"æ£€æŸ¥è¡¨ '{sanitized_base_name}' æ˜¯å¦å­˜åœ¨æ—¶å‡ºé”™ã€‚")
        return False, sanitized_base_name, 'fail' # Fail safe

    if not table_exists:
        # è¡¨ä¸å­˜åœ¨ï¼Œç›´æ¥è¿›è¡Œåˆ›å»ºï¼ˆä½¿ç”¨replaceç­–ç•¥ï¼‰
        logger.info(f"Table '{sanitized_base_name}' does not exist. Proceeding with creation.")
        return True, sanitized_base_name, 'replace'

    # --- è¡¨å­˜åœ¨ï¼Œæ£€æŸ¥æ˜¯å¦å·²ç¡®è®¤ --- 
    if st.session_state[confirmed_key]:
        final_name = st.session_state.get(f"{session_key_base}_final_name", sanitized_base_name)
        final_strategy = st.session_state.get(f"{session_key_base}_final_strategy", 'skip') # é»˜è®¤ä¸º skipï¼Œå¦‚æœæ²¡å­˜
        final_proceed = st.session_state.get(f"{session_key_base}_final_proceed", False)
        # logger.debug(f"Returning stored state for confirmed table '{sanitized_base_name}': {final_proceed}, {final_name}, {final_strategy}")
        return final_proceed, final_name, final_strategy

    # --- è¡¨å­˜åœ¨ä¸”æœªç¡®è®¤ï¼Œæ˜¾ç¤ºç”¨æˆ·é€‰é¡¹ --- 
    st.warning(f"æ•°æ®åº“ä¸­å·²å­˜åœ¨åä¸º '{sanitized_base_name}' çš„è¡¨ (æ¥è‡ªæ–‡ä»¶ '{original_table_name}')ã€‚è¯·é€‰æ‹©æ“ä½œï¼š")

    # ä½¿ç”¨åˆ—å¸ƒå±€ä¼˜åŒ–æ˜¾ç¤º
    col1, col2 = st.columns([3, 1]) # è°ƒæ•´æ¯”ä¾‹ç»™å•é€‰æŒ‰é’®æ›´å¤šç©ºé—´

    with col1:
        action = st.radio(
            "é€‰æ‹©æ“ä½œï¼š",
            ('æ›¿æ¢ç°æœ‰è¡¨', 'è¿½åŠ åˆ°ç°æœ‰è¡¨', 'é‡å‘½åæ–°è¡¨', 'è·³è¿‡æ­¤æ–‡ä»¶'),
            key=action_key, # ä½¿ç”¨ session state key
            horizontal=True,
            label_visibility="collapsed"
        )

        # å¦‚æœé€‰æ‹©é‡å‘½åï¼Œæ˜¾ç¤ºè¾“å…¥æ¡†
        rename_input_visible = (action == 'é‡å‘½åæ–°è¡¨')
        if rename_input_visible:
            new_table_name_input = st.text_input(
                "è¾“å…¥æ–°è¡¨åï¼š",
                value=st.session_state[rename_key],
                key=rename_key # ä½¿ç”¨ session state key
            )
        else:
            # éšè—æ—¶ä»ç„¶éœ€è¦ä¸€ä¸ªå ä½ç¬¦æˆ–é€»è¾‘å¤„ç†ï¼Œç¡®ä¿keyå­˜åœ¨
            new_table_name_input = st.session_state[rename_key] # ä¿ç•™çŠ¶æ€ä½†ä¸æ˜¾ç¤º

    with col2:
        # ç¡®è®¤æŒ‰é’®ï¼Œæ¯ä¸ªè¡¨å®ä¾‹ä¸€ä¸ªç‹¬ç«‹çš„æŒ‰é’®
        confirm_pressed = st.button("ç¡®è®¤æ“ä½œ", key=confirm_key)

    # --- å¤„ç†ç¡®è®¤æŒ‰é’®ç‚¹å‡» --- 
    if confirm_pressed:
        logger.info(f"Confirmation received for table '{sanitized_base_name}'. Action: {action}")
        final_table_name = sanitized_base_name
        if_exists_strategy = 'fail' # Default to fail/skip if logic below doesn't set
        proceed = False

        if action == 'æ›¿æ¢ç°æœ‰è¡¨':
            if_exists_strategy = 'replace'
            proceed = True
        elif action == 'è¿½åŠ åˆ°ç°æœ‰è¡¨':
            if_exists_strategy = 'append'
            proceed = True
        elif action == 'é‡å‘½åæ–°è¡¨':
            # æ¸…ç†å¹¶éªŒè¯æ–°è¡¨å
            proposed_name = ''.join(filter(str.isalnum, new_table_name_input)).lower()
            if not proposed_name:
                st.error("æ–°è¡¨åæ— æ•ˆï¼Œä¸èƒ½ä¸ºç©ºæˆ–åªåŒ…å«ç‰¹æ®Šå­—ç¬¦ã€‚è¯·é‡æ–°è¾“å…¥å¹¶ç¡®è®¤ã€‚")
                return False, sanitized_base_name, 'pending' # ç‰¹æ®ŠçŠ¶æ€è¡¨ç¤ºç­‰å¾…ç”¨æˆ·ä¿®æ­£
            elif proposed_name == sanitized_base_name:
                st.error(f"æ–°è¡¨å '{proposed_name}' ä¸ç°æœ‰è¡¨åç›¸åŒã€‚è¯·é€‰æ‹©å…¶ä»–æ“ä½œæˆ–è¾“å…¥ä¸åŒçš„æ–°è¡¨åã€‚")
                return False, sanitized_base_name, 'pending'
            else:
                # æ£€æŸ¥é‡å‘½åçš„ç›®æ ‡è¡¨æ˜¯å¦ä¹Ÿå­˜åœ¨
                rename_target_exists = check_table_exists(conn, proposed_name)
                if rename_target_exists is None:
                    st.error(f"æ£€æŸ¥ç›®æ ‡æ–°è¡¨å '{proposed_name}' æ˜¯å¦å­˜åœ¨æ—¶å‡ºé”™ã€‚")
                    return False, sanitized_base_name, 'fail'
                elif rename_target_exists:
                    st.error(f"ç›®æ ‡æ–°è¡¨å '{proposed_name}' ä¹Ÿå·²å­˜åœ¨ã€‚è¯·é€‰æ‹©ä¸åŒçš„åç§°æˆ–æ“ä½œã€‚")
                    return False, sanitized_base_name, 'pending'
                else:
                    final_table_name = proposed_name
                    if_exists_strategy = 'replace' # å¯¹æ–°å‘½åçš„è¡¨æ€»æ˜¯åˆ›å»º/æ›¿æ¢
                    proceed = True
        elif action == 'è·³è¿‡æ­¤æ–‡ä»¶':
            if_exists_strategy = 'skip'
            proceed = False
            st.info(f"å·²é€‰æ‹©è·³è¿‡æ–‡ä»¶ '{original_table_name}' çš„æ•°æ®åº“æ“ä½œã€‚")
        
        # åªæœ‰åœ¨ç¡®è®¤åä¸”æ“ä½œä¸æ˜¯ pending æ—¶ï¼Œæ‰æ ‡è®°ä¸ºå·²ç¡®è®¤å¹¶å­˜å‚¨çŠ¶æ€
        if if_exists_strategy != 'pending':
            st.session_state[confirmed_key] = True
            # å­˜å‚¨æœ€ç»ˆå†³å®šï¼Œä»¥ä¾¿ä¸‹æ¬¡è°ƒç”¨æ—¶ç›´æ¥è¿”å›
            st.session_state[f"{session_key_base}_final_proceed"] = proceed
            st.session_state[f"{session_key_base}_final_name"] = final_table_name
            st.session_state[f"{session_key_base}_final_strategy"] = if_exists_strategy
            logger.info(f"State confirmed and stored for '{sanitized_base_name}': proceed={proceed}, name={final_table_name}, strategy={if_exists_strategy}")

        logger.info(f"_handle_table_existence returning: proceed={proceed}, name={final_table_name}, strategy={if_exists_strategy}")
        return proceed, final_table_name, if_exists_strategy

    else:
        # å¦‚æœæŒ‰é’®æœªè¢«æŒ‰ä¸‹ï¼Œè¡¨ç¤ºç”¨æˆ·å°šæœªç¡®è®¤ï¼Œä¸è¿›è¡Œä»»ä½•æ•°æ®åº“æ“ä½œ
        # è¿”å›ä¸€ä¸ªè¡¨ç¤ºâ€œå¾…å®šâ€çš„çŠ¶æ€
        # logger.debug(f"No confirmation yet for table '{sanitized_base_name}'. Returning 'pending'.")
        return False, sanitized_base_name, 'pending'

# --- å¤„ç†è¡¨æ ¼--- 
def process_tabular_file(st, uploaded_file, conn):
    """å¤„ç†è¡¨æ ¼æ–‡ä»¶(CSV, XLS, XLSX)ï¼Œæ”¯æŒExcelå¤šå·¥ä½œè¡¨ï¼Œå¹¶åœ¨è¡¨å­˜åœ¨æ—¶è¯¢é—®ç”¨æˆ·æ“ä½œã€‚"""
    created_tables = []
    try:
        base_file_name = os.path.splitext(uploaded_file.name)[0]
        # ä½¿ç”¨åŸå§‹æ–‡ä»¶åç”ŸæˆåŸºç¡€è¡¨åï¼Œç¨åæ¸…ç†
        original_base_table_name = base_file_name 

        if uploaded_file.name.endswith('.csv'):
            # å¢å¼ºçš„CSVè§£æï¼šå¤šç§ç¼–ç å°è¯•å’Œæ”¹è¿›é”™è¯¯å¤„ç†
            raw_data = uploaded_file.read()
            result = chardet.detect(raw_data)
            detected_encoding = result['encoding']
            logger.info(f"Detected encoding for {uploaded_file.name}: {detected_encoding}")

            # å¤šç§ç¼–ç å°è¯•åˆ—è¡¨
            encodings_to_try = ['utf-8', 'gbk', 'gb2312', 'latin1', detected_encoding]
            encodings_to_try = [enc for enc in encodings_to_try if enc is not None]
            
            df = None
            successful_encoding = None
            
            for encoding in encodings_to_try:
                try:
                    # é‡ç½®æ–‡ä»¶æŒ‡é’ˆä½ç½®
                    uploaded_file.seek(0)
                    df = pd.read_csv(io.BytesIO(raw_data), encoding=encoding, escapechar='\\')
                    
                    # æ£€æŸ¥åˆ—åæ˜¯å¦ä¸ºæ•´æ•°ç±»å‹ï¼Œå¦‚æœæ˜¯åˆ™é‡æ–°è¯»å–ä¸ºæ— æ ‡é¢˜è¡Œ
                    if all(isinstance(col, int) for col in df.columns) or len(df) == 0:
                        uploaded_file.seek(0)
                        df = pd.read_csv(io.BytesIO(raw_data), encoding=encoding, escapechar='\\', header=None)
                        df.columns = [f'col_{i}' for i in range(len(df.columns))]
                    
                    # éªŒè¯æ•°æ®æœ‰æ•ˆæ€§
                    if not df.empty and len(df.columns) > 0:
                        successful_encoding = encoding
                        logger.info(f"Successfully read CSV {uploaded_file.name} with encoding: {encoding}")
                        break
                        
                except UnicodeDecodeError:
                    logger.warning(f"Encoding {encoding} failed for {uploaded_file.name}, trying next...")
                    continue
                except Exception as e:
                    logger.warning(f"Error reading CSV {uploaded_file.name} with encoding {encoding}: {e}")
                    continue

            if df is None:
                handle_error(
                    st, 
                    f"æ— æ³•è§£ç CSVæ–‡ä»¶ '{uploaded_file.name}'ï¼Œå·²å°è¯•å¤šç§ç¼–ç æ ¼å¼ã€‚",
                    error_code="CSV_DECODE_ERROR",
                    user_suggestion="è¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹æ˜¯å¦ä¸ºæœ‰æ•ˆçš„CSVæ ¼å¼ï¼Œæˆ–å°è¯•å°†æ–‡ä»¶ä¿å­˜ä¸ºUTF-8ç¼–ç åé‡æ–°ä¸Šä¼ ã€‚"
                )
                return None
            
            if df.empty or len(df.columns) == 0:
                handle_error(
                    st,
                    f"CSVæ–‡ä»¶ '{uploaded_file.name}' ä¸ºç©ºæˆ–æ²¡æœ‰æœ‰æ•ˆæ•°æ®åˆ—",
                    error_code="CSV_EMPTY_ERROR",
                    user_suggestion="è¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹ï¼Œç¡®ä¿åŒ…å«æœ‰æ•ˆçš„æ•°æ®ã€‚"
                )
                return None

            # è®°å½•æˆåŠŸä½¿ç”¨çš„ç¼–ç 
            logger.info(f"CSV {uploaded_file.name} successfully parsed using encoding: {successful_encoding}")
            
            # åœ¨æ’å…¥å‰æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨å¹¶è·å–ç”¨æˆ·é€‰æ‹©
            proceed, final_table_name, if_exists_strategy = _handle_table_existence(st, conn, original_base_table_name)

            if proceed:
                if insert_dataframe_to_db(st, df, final_table_name, conn, if_exists=if_exists_strategy):
                    st.success(f"CSV æ–‡ä»¶ '{uploaded_file.name}' å·²æˆåŠŸæ“ä½œè¡¨ '{final_table_name}' (ç­–ç•¥: {if_exists_strategy})ã€‚")
                    created_tables.append(final_table_name)
                else:
                    st.error(f"æ“ä½œ CSV æ–‡ä»¶ '{uploaded_file.name}' åˆ°è¡¨ '{final_table_name}' å¤±è´¥ã€‚")
            else:
                # st.info(f"è·³è¿‡æ–‡ä»¶ '{uploaded_file.name}' çš„æ•°æ®åº“æ“ä½œã€‚")
                pass

        elif uploaded_file.name.endswith(('.xls', '.xlsx')):
            # å¢å¼ºçš„Excelè§£æï¼šå¤šå¼•æ“æ”¯æŒ
            engines = ['calamine', 'openpyxl', 'xlrd']
            excel_data = None
            successful_engine = None
            
            for engine in engines:
                try:
                    uploaded_file.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
                    excel_data = pd.read_excel(uploaded_file, sheet_name=None, engine=engine)
                    if excel_data:
                        successful_engine = engine
                        logger.info(f"Successfully read Excel {uploaded_file.name} using engine: {engine}")
                        break
                except ImportError:
                    logger.warning(f"Engine {engine} not available for {uploaded_file.name}")
                    continue
                except Exception as e:
                    logger.warning(f"Engine {engine} failed for {uploaded_file.name}: {e}")
                    continue
            
            if excel_data is None:
                handle_error(
                    st,
                    f"æ— æ³•è¯»å–Excelæ–‡ä»¶ '{uploaded_file.name}'ï¼Œå·²å°è¯•æ‰€æœ‰å¯ç”¨çš„è§£æå¼•æ“ã€‚",
                    error_code="EXCEL_READ_ERROR",
                    user_suggestion="è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼Œæˆ–å°è¯•å°†æ–‡ä»¶ä¿å­˜ä¸ºè¾ƒæ–°çš„Excelæ ¼å¼åé‡æ–°ä¸Šä¼ ã€‚"
                )
                return None

            if not excel_data:
                st.warning(f"Excel æ–‡ä»¶ '{uploaded_file.name}' ä¸ºç©ºæˆ–æ— æ³•è¯»å–ã€‚")
                return None

            sheet_items = list(excel_data.items())

            # Filter out empty sheets
            non_empty_sheets = [(name, df) for name, df in sheet_items if not df.empty]

            if not non_empty_sheets:
                st.warning(f"Excel æ–‡ä»¶ '{uploaded_file.name}' æ‰€æœ‰å·¥ä½œè¡¨å‡ä¸ºç©ºã€‚")
                return None

            for sheet_name, df in non_empty_sheets:
                # Determine original table name based on sheet
                if len(non_empty_sheets) == 1:
                    original_table_name = original_base_table_name
                else:
                    # Sanitize sheet name for table name part
                    cleaned_sheet_name = ''.join(filter(str.isalnum, str(sheet_name))).lower()
                    # å¦‚æœæœ‰å¤šä¸ªéç©ºsheetï¼Œç›´æ¥ä½¿ç”¨æ¸…ç†åçš„sheetåï¼Œå¦‚æœæ¸…ç†åä¸ºç©ºï¼Œåˆ™ä½¿ç”¨é€šç”¨åç§°
                    original_table_name = cleaned_sheet_name if cleaned_sheet_name else f"sheet_{len(created_tables) + 1}"

                # åœ¨æ’å…¥å‰æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨å¹¶è·å–ç”¨æˆ·é€‰æ‹©
                proceed, final_table_name, if_exists_strategy = _handle_table_existence(st, conn, original_table_name)

                if proceed:
                    if insert_dataframe_to_db(st, df, final_table_name, conn, if_exists=if_exists_strategy):
                        st.success(f"EXCELè¡¨ '{base_file_name}'-'{sheet_name}' å·²æˆåŠŸæ“ä½œè¡¨ '{final_table_name}' (ç­–ç•¥: {if_exists_strategy})ã€‚")
                        created_tables.append(final_table_name)
                    else:
                        st.error(f"æ“ä½œå·¥ä½œè¡¨ '{sheet_name}' åˆ°è¡¨ '{final_table_name}' å¤±è´¥ã€‚")
                else:
                     # st.info(f"è·³è¿‡å·¥ä½œè¡¨ '{sheet_name}' çš„æ•°æ®åº“æ“ä½œã€‚")
                     pass
        else:
            st.warning(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {uploaded_file.name}")
            return None

        return created_tables if created_tables else None

    except Exception as e:
        st.error(f"å¤„ç†è¡¨æ ¼æ–‡ä»¶ '{uploaded_file.name}' æ—¶å‡ºé”™: {e}")
        logger.error(f"Error processing tabular file {uploaded_file.name}: {e}", exc_info=True)
        return None

# --- å¤„ç†OCR--- 
def process_ocr(st, uploaded_file, conn, vl_client, vl_model_name, force_process=False, target_table_name=None, ocr_if_exists='replace'):
    """å¤„ç†å›¾ç‰‡æˆ–PDFæ–‡ä»¶è¿›è¡ŒOCRï¼Œå¹¶åœ¨è¡¨å­˜åœ¨æ—¶è¯¢é—®ç”¨æˆ·æ“ä½œï¼ˆé™¤éå¼ºåˆ¶æ‰§è¡Œï¼‰ï¼Œç„¶åå­˜å…¥æ•°æ®åº“ã€‚
    
    Args:
        force_process (bool): å¦‚æœä¸ºTrueï¼Œåˆ™è·³è¿‡å­˜åœ¨æ€§æ£€æŸ¥å’Œç”¨æˆ·äº¤äº’ï¼Œç›´æ¥ä½¿ç”¨æä¾›çš„ç­–ç•¥ã€‚
        target_table_name (str): å½“ force_process ä¸º True æ—¶ï¼ŒæŒ‡å®šè¦æ“ä½œçš„ç›®æ ‡è¡¨åã€‚
        ocr_if_exists (str): å½“ force_process ä¸º True æ—¶ï¼ŒæŒ‡å®šè¡¨å­˜åœ¨æ—¶çš„æ“ä½œç­–ç•¥ã€‚
    """
    try:
        file_name_base = os.path.splitext(uploaded_file.name)[0]
        original_table_name = file_name_base # ä½¿ç”¨åŸå§‹æ–‡ä»¶åä½œä¸ºåŸºç¡€

        proceed = False
        final_table_name = None
        if_exists_strategy = 'fail'

        if force_process:
            # å¼ºåˆ¶å¤„ç†ï¼Œä½¿ç”¨ä¼ å…¥çš„å‚æ•°
            proceed = True
            final_table_name = target_table_name
            if_exists_strategy = ocr_if_exists
            logger.info(f"Force processing OCR for {uploaded_file.name}. Target: {final_table_name}, Strategy: {if_exists_strategy}")
        else:
            # æ­£å¸¸æµç¨‹ï¼Œæ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨å¹¶è·å–ç”¨æˆ·ç¡®è®¤
            proceed, final_table_name, if_exists_strategy = _handle_table_existence(st, conn, original_table_name)
            if if_exists_strategy == 'pending':
                return None # ç­‰å¾…ç”¨æˆ·ç¡®è®¤

        if not proceed:
            if if_exists_strategy != 'skip': # é¿å…é‡å¤æ˜¾ç¤ºè·³è¿‡ä¿¡æ¯
                 # st.info(f"è·³è¿‡æ–‡ä»¶ '{uploaded_file.name}' (OCR) çš„æ•°æ®åº“æ“ä½œã€‚")
                 pass
            return None

        # --- æ‰§è¡Œ OCR å’Œæ•°æ®åº“æ“ä½œ --- 
        file_bytes = uploaded_file.getvalue()
        df = None
        image_base64_list = []

        if uploaded_file.type.startswith('image/'):
            logger.info(f"Processing image file {uploaded_file.name} for OCR.")
            # å¢å¼ºçš„å›¾ç‰‡æ ¼å¼æ”¯æŒï¼šç»Ÿä¸€è½¬æ¢ä¸ºRGBæ ¼å¼
            try:
                from PIL import Image
                img = Image.open(io.BytesIO(file_bytes))
                img = img.convert('RGB')  # ç»Ÿä¸€è½¬æ¢ä¸ºRGBæ ¼å¼
                buffer = io.BytesIO()
                img.save(buffer, format='JPEG')
                img_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
                image_base64_list.append(img_base64)
                img.close()  # é‡Šæ”¾å†…å­˜
                buffer.close()
            except ImportError:
                logger.warning("PIL not available, using raw image data")
                img_base64 = base64.b64encode(file_bytes).decode('utf-8')
                image_base64_list.append(img_base64)
            except Exception as e:
                logger.error(f"Image conversion failed for {uploaded_file.name}: {e}")
                img_base64 = base64.b64encode(file_bytes).decode('utf-8')
                image_base64_list.append(img_base64)
                
        elif uploaded_file.type == 'application/pdf':
            logger.info(f"Processing PDF file {uploaded_file.name} for OCR.")
            try:
                doc = fitz.Document(stream=file_bytes, filetype="pdf")
                num_pages_to_process = min(3, len(doc))  # é™åˆ¶å¤„ç†é¡µæ•°ä»¥èŠ‚çœå†…å­˜
                
                for page_num in range(num_pages_to_process):
                    try:
                        page = doc.load_page(page_num)
                        # ä¼˜åŒ–DPIè®¾ç½®ï¼šå¹³è¡¡è´¨é‡å’Œå†…å­˜ä½¿ç”¨
                        pix = page.get_pixmap(dpi=200)  # é™ä½DPIä»300åˆ°200
                        img_bytes_page = pix.tobytes("jpeg")
                        img_base64 = base64.b64encode(img_bytes_page).decode('utf-8')
                        image_base64_list.append(img_base64)
                        # æ˜¾å¼é‡Šæ”¾å†…å­˜
                        del pix
                    except Exception as e:
                        logger.error(f"Error processing page {page_num} in {uploaded_file.name}: {e}")
                        continue
                
                doc.close()
                logger.info(f"Processed {num_pages_to_process} pages from {uploaded_file.name}")
            except Exception as e:
                logger.error(f"Error opening PDF {uploaded_file.name}: {e}")
                st.error(f"æ— æ³•æ‰“å¼€PDFæ–‡ä»¶ '{uploaded_file.name}'ï¼Œæ–‡ä»¶å¯èƒ½å·²æŸåã€‚")
                return None
        else:
            st.warning(f"ä¸æ”¯æŒçš„OCRæ–‡ä»¶ç±»å‹: {uploaded_file.name} ({uploaded_file.type})")
            return None
            
        df_str = call_vl_api(st, vl_client, vl_model_name, image_base64_list=image_base64_list)

        if df_str is not None and isinstance(df_str, str):
            try:
                # å°†CSVå­—ç¬¦ä¸²è½¬æ¢ä¸ºDataFrame
                df = pd.read_csv(io.StringIO(df_str))
                if not df.empty:
                    logger.info(f"OCR successful for {uploaded_file.name}. Extracted DataFrame shape: {df.shape}")
                    
                    # ä½¿ç”¨ç¡®è®¤åçš„è¡¨åå’Œç­–ç•¥è¿›è¡Œæ•°æ®åº“æ“ä½œ
                    if insert_dataframe_to_db(st, df, final_table_name, conn, if_exists=if_exists_strategy):
                        st.success(f"æ–‡ä»¶ '{uploaded_file.name}' é€šè¿‡OCRå¤„ç†åæˆåŠŸæ“ä½œè¡¨ '{final_table_name}' (ç­–ç•¥: {if_exists_strategy})ã€‚")
                        return final_table_name
                    else:
                        st.error(f"OCRå¤„ç†åï¼Œæ“ä½œæ•°æ®åˆ°è¡¨ '{final_table_name}' å¤±è´¥ã€‚")
                        return None
                else:
                    st.warning(f"æœªèƒ½ä»æ–‡ä»¶ '{uploaded_file.name}' ä¸­æå–åˆ°è¡¨æ ¼æ•°æ® (OCRç»“æœä¸ºç©º)ã€‚")
                    logger.warning(f"OCR for {uploaded_file.name} resulted in an empty DataFrame.")
                    return None
            except Exception as e:
                st.error(f"å¤„ç†OCRç»“æœæ—¶å‡ºé”™: {e}")
                logger.error(f"Error processing OCR result for {uploaded_file.name}: {e}", exc_info=True)
                return None
        elif df_str is None:
             # Error/warning already shown by call_vl_api
             logger.warning(f"OCR call for {uploaded_file.name} returned None.")
             return None
        else: # å¦‚æœ call_vl_api è¿”å›äº†éå­—ç¬¦ä¸²ï¼ˆä¾‹å¦‚ DataFrameï¼‰ï¼Œè¿™ä¸ç¬¦åˆé¢„æœŸ
            st.error(f"OCR API è¿”å›äº†æ„å¤–çš„ç±»å‹: {type(df_str)}ã€‚æœŸæœ›æ˜¯ CSV å­—ç¬¦ä¸²ã€‚")
            logger.error(f"Unexpected return type from call_vl_api for {uploaded_file.name}: {type(df_str)}")
            return None

    except Exception as e:
        st.error(f"å¤„ç†OCRæ–‡ä»¶ '{uploaded_file.name}' æ—¶å‡ºé”™: {e}")
        logger.error(f"Error processing OCR file {uploaded_file.name}: {e}", exc_info=True)